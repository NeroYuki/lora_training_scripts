bucket_reso_steps = 64
cache_latents = true
cache_latents_to_disk = true
cache_text_encoder_outputs = false
caption_extension = ".txt"
clip_skip = 2
debiased_estimation_loss = true
dynamo_backend = "no"
epoch = 6
full_bf16 = true
gradient_accumulation_steps = 1
gradient_checkpointing = true
huber_c = 0.1
huber_schedule = "snr"
learning_rate = 1.0
logging_dir = "D:/AIstuff/kohya_ss/dataset\\log"
loss_type = "l2"
lr_scheduler = "cosine"
lr_scheduler_args = []
lr_scheduler_num_cycles = 1
lr_scheduler_power = 1
max_bucket_reso = 2048
max_data_loader_n_workers = 0
max_grad_norm = 1
max_timestep = 1000
max_token_length = 75
max_train_epochs = 6
max_train_steps = 1500
min_bucket_reso = 256
min_snr_gamma = 5
mixed_precision = "bf16"
network_alpha = 32
network_args = []
network_dim = 32
network_module = "networks.lora"
network_train_unet_only = false
no_half_vae = true
noise_offset_type = "Original"
optimizer_args = [ "weight_decay=0.1", "decouple=True", "use_bias_correction=True", "safeguard_warmup=False", "betas=0.9,0.99",]
optimizer_type = "Prodigy"
output_dir = "D:/AIstuff/kohya_ss/dataset\\model"
output_name = "test_stella_fast"
pretrained_model_name_or_path = "D:/AIstuff/stable-diffusion-webui/models/Stable-diffusion/noobaixl_v1_1.safetensors"
prior_loss_weight = 1
resolution = "1024,1024"
sample_every_n_epochs = 1
sample_prompts = "D:/AIstuff/kohya_ss/dataset\\model\\prompt.txt"
sample_sampler = "euler_a"
save_every_n_epochs = 1
save_model_as = "safetensors"
save_precision = "bf16"
train_batch_size = 3
train_data_dir = "D:/AIstuff/kohya_ss/dataset\\img"
training_comment = "Test automated training pipeline"
unet_lr = 1
text_encoder_lr = 1
xformers = true
